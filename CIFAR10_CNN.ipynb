{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPool2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "(X_train_unscaled, y_train), (X_test_unscaled, y_test) = cifar10.load_data()\n",
    "\n",
    "print(f\"X_train shape: {np.shape(X_train_unscaled)}\")\n",
    "print(f\"y_train shape: {np.shape(y_train)}\")\n",
    "print(f\"X_test shape: {np.shape(X_test_unscaled)}\")\n",
    "print(f\"y_test shape: {np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the normalize the data and convert targets to one hot encoding\n",
    "X_train_valid, X_test = X_train_unscaled/255.0, X_test_unscaled/255.0\n",
    "\n",
    "y_cat_train_valid = to_categorical(y_train)\n",
    "y_cat_test = to_categorical(y_test)\n",
    "\n",
    "#split the training dataset again to produce a validation set\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_valid, y_cat_train, y_cat_valid = train_test_split(X_train_valid, y_cat_train_valid, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "INPUT_SHAPE = (32,32,3)\n",
    "KERNEL_SIZE = (3,3)\n",
    "model = Sequential()\n",
    "\n",
    "#common to increase number of filters as we add convolutional layers (pooling reduces by 2 so we double filters)\n",
    "\n",
    "#conv layers\n",
    "model.add(Conv2D(filters=32, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "#pooling\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#droput\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#conv layers\n",
    "model.add(Conv2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "#pooling\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#droput\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#conv layers\n",
    "model.add(Conv2D(filters=128, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "#pooling\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#droput\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "METRICS = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 420,586\n",
      "Trainable params: 419,690\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1172/1172 [==============================] - 319s 271ms/step - loss: 1.7371 - accuracy: 0.3651 - precision: 0.6125 - recall: 0.1561 - val_loss: 2.5544 - val_accuracy: 0.2983 - val_precision: 0.3218 - val_recall: 0.1892\n",
      "Epoch 2/20\n",
      "1172/1172 [==============================] - 290s 248ms/step - loss: 1.2739 - accuracy: 0.5465 - precision: 0.7246 - recall: 0.3714 - val_loss: 1.1962 - val_accuracy: 0.5804 - val_precision: 0.7235 - val_recall: 0.4617\n",
      "Epoch 3/20\n",
      "1172/1172 [==============================] - 89s 75ms/step - loss: 1.0626 - accuracy: 0.6318 - precision: 0.7738 - recall: 0.4905 - val_loss: 0.8947 - val_accuracy: 0.6810 - val_precision: 0.7973 - val_recall: 0.5743\n",
      "Epoch 4/20\n",
      "1172/1172 [==============================] - 221s 189ms/step - loss: 0.9317 - accuracy: 0.6786 - precision: 0.7984 - recall: 0.5625 - val_loss: 0.8185 - val_accuracy: 0.7190 - val_precision: 0.8055 - val_recall: 0.6351\n",
      "Epoch 5/20\n",
      "1172/1172 [==============================] - 434s 370ms/step - loss: 0.8414 - accuracy: 0.7108 - precision: 0.8191 - recall: 0.6096 - val_loss: 0.7872 - val_accuracy: 0.7303 - val_precision: 0.8222 - val_recall: 0.6453\n",
      "Epoch 6/20\n",
      "1172/1172 [==============================] - 386s 329ms/step - loss: 0.7715 - accuracy: 0.7383 - precision: 0.8307 - recall: 0.6454 - val_loss: 0.6922 - val_accuracy: 0.7635 - val_precision: 0.8373 - val_recall: 0.6968\n",
      "Epoch 7/20\n",
      "1172/1172 [==============================] - 90s 77ms/step - loss: 0.7057 - accuracy: 0.7604 - precision: 0.8438 - recall: 0.6816 - val_loss: 0.6683 - val_accuracy: 0.7730 - val_precision: 0.8571 - val_recall: 0.6950\n",
      "Epoch 8/20\n",
      "1172/1172 [==============================] - 63s 54ms/step - loss: 0.6577 - accuracy: 0.7725 - precision: 0.8510 - recall: 0.7017 - val_loss: 0.6768 - val_accuracy: 0.7796 - val_precision: 0.8535 - val_recall: 0.7115\n",
      "Epoch 9/20\n",
      "1172/1172 [==============================] - 415s 354ms/step - loss: 0.6160 - accuracy: 0.7876 - precision: 0.8594 - recall: 0.7223 - val_loss: 0.6325 - val_accuracy: 0.7902 - val_precision: 0.8489 - val_recall: 0.7379\n",
      "Epoch 10/20\n",
      "1172/1172 [==============================] - 444s 379ms/step - loss: 0.5784 - accuracy: 0.8016 - precision: 0.8663 - recall: 0.7437 - val_loss: 0.6895 - val_accuracy: 0.7739 - val_precision: 0.8424 - val_recall: 0.7219\n",
      "Epoch 11/20\n",
      "1172/1172 [==============================] - 437s 373ms/step - loss: 0.5494 - accuracy: 0.8118 - precision: 0.8737 - recall: 0.7550 - val_loss: 0.5917 - val_accuracy: 0.8066 - val_precision: 0.8598 - val_recall: 0.7606\n",
      "Epoch 12/20\n",
      "1172/1172 [==============================] - 437s 373ms/step - loss: 0.5192 - accuracy: 0.8220 - precision: 0.8795 - recall: 0.7722 - val_loss: 0.6519 - val_accuracy: 0.7942 - val_precision: 0.8459 - val_recall: 0.7500\n",
      "Epoch 13/20\n",
      "1172/1172 [==============================] - 468s 399ms/step - loss: 0.4909 - accuracy: 0.8341 - precision: 0.8860 - recall: 0.7854 - val_loss: 0.5937 - val_accuracy: 0.8140 - val_precision: 0.8607 - val_recall: 0.7750\n",
      "Epoch 14/20\n",
      "1172/1172 [==============================] - 442s 377ms/step - loss: 0.4677 - accuracy: 0.8392 - precision: 0.8872 - recall: 0.7960 - val_loss: 0.5795 - val_accuracy: 0.8182 - val_precision: 0.8638 - val_recall: 0.7802\n",
      "Epoch 15/20\n",
      "1172/1172 [==============================] - 435s 371ms/step - loss: 0.4503 - accuracy: 0.8465 - precision: 0.8921 - recall: 0.8047 - val_loss: 0.6303 - val_accuracy: 0.8018 - val_precision: 0.8485 - val_recall: 0.7654\n",
      "Epoch 16/20\n",
      "1172/1172 [==============================] - 439s 374ms/step - loss: 0.4254 - accuracy: 0.8526 - precision: 0.8964 - recall: 0.8138 - val_loss: 0.6460 - val_accuracy: 0.7947 - val_precision: 0.8398 - val_recall: 0.7574\n",
      "Epoch 17/20\n",
      "1172/1172 [==============================] - 411s 350ms/step - loss: 0.4143 - accuracy: 0.8573 - precision: 0.8984 - recall: 0.8191 - val_loss: 0.5797 - val_accuracy: 0.8174 - val_precision: 0.8627 - val_recall: 0.7832\n",
      "Epoch 18/20\n",
      "1172/1172 [==============================] - 438s 373ms/step - loss: 0.3966 - accuracy: 0.8637 - precision: 0.9023 - recall: 0.8271 - val_loss: 0.5811 - val_accuracy: 0.8222 - val_precision: 0.8604 - val_recall: 0.7926\n",
      "Epoch 19/20\n",
      "1172/1172 [==============================] - 428s 365ms/step - loss: 0.3813 - accuracy: 0.8692 - precision: 0.9057 - recall: 0.8371 - val_loss: 0.5548 - val_accuracy: 0.8286 - val_precision: 0.8659 - val_recall: 0.7978\n",
      "Epoch 20/20\n",
      "1172/1172 [==============================] - 448s 382ms/step - loss: 0.3706 - accuracy: 0.8740 - precision: 0.9106 - recall: 0.8435 - val_loss: 0.6092 - val_accuracy: 0.8145 - val_precision: 0.8509 - val_recall: 0.7864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb0b2b7070>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "num_epochs = 20\n",
    "model.fit(X_train, y_cat_train, epochs=num_epochs, validation_data=(X_valid,y_cat_valid), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6093 - accuracy: 0.8081 - precision: 0.8456 - recall: 0.7807\n",
      "accuracy: 0.8080999851226807\n",
      "precision: 0.845553994178772\n",
      "recall: 0.7807000279426575\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on the test set\n",
    "test_results = model.evaluate(X_test, y_cat_test)\n",
    "loss = test_results[0]\n",
    "accuracy = test_results[1]\n",
    "precision = test_results[2]\n",
    "recall = test_results[3]\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
